{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Datkhoo25/insurance_risk_prediction/blob/main/6_(XGB%2C_RF)_RFE_DT_Sim_Impute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69OhFAnVx55a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a826fb55-2a18-40b8-9fb9-d0f021b7f7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', timeout_ms=300000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r183ZGTona4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openpyxl\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "from scipy.optimize import fmin_powell\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import ensemble\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,  roc_auc_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, r2_score\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Fn2wsFa_EL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df4c733-d8d9-4184-bb56-b34c06a3808d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tz_IeV32WKRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59785d6-09a2-44b1-caad-3d3bb8adff8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-670abaa5fb26>:13: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  import kerastuner as kt\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-tuner\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.initializers import HeNormal, GlorotNormal, LecunNormal\n",
        "\n",
        "from keras import regularizers\n",
        "from keras.layers import Dropout\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "\n",
        "import kerastuner as kt\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner import Objective\n",
        "\n",
        "from keras.callbacks import History\n",
        "from keras.callbacks import Callback, EarlyStopping\n",
        "from keras.metrics import Accuracy, Recall, Precision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0ukCAVRrNry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed121680-745d-407f-b8f5-a2bfa57f36f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sheet: X_train_sim_imp_wNA_dt_rfe\n",
            "\n",
            "Sheet: X_val_sim_imp_wNA_dt_rfe\n",
            "\n",
            "Sheet: test_df_sim_imp_wNA_dt_rfe\n",
            "\n",
            "Sheet: y_train\n",
            "\n",
            "Sheet: y_val\n"
          ]
        }
      ],
      "source": [
        "# Specify the path to your Excel file\n",
        "workbook_path = '/content/drive/MyDrive/Colab Notebooks/Insurance Dataset/Preprocessing_Checkpoint/Sim_Impute_wNA_dt_rfe.xlsx'\n",
        "\n",
        "# Load the workbook\n",
        "wb = openpyxl.load_workbook(workbook_path)\n",
        "\n",
        "# Get sheet names\n",
        "sheet_names = wb.sheetnames\n",
        "\n",
        "# Container for DataFrames\n",
        "dfs = {}\n",
        "\n",
        "# Iterate through each sheet\n",
        "for sheet_name in sheet_names:\n",
        "    print(f\"\\nSheet: {sheet_name}\")\n",
        "    sheet = wb[sheet_name]\n",
        "\n",
        "    # Extract headers (first row)\n",
        "    headers = [cell.value for cell in sheet[1]]\n",
        "    # print(f\"Headers: {headers}\")\n",
        "\n",
        "    # Extract data rows\n",
        "    data = []\n",
        "    for row in sheet.iter_rows(min_row=2, values_only=True):\n",
        "        data.append(row)\n",
        "    # print(\"Data:\")\n",
        "    # for row in data:\n",
        "    #     print(row)\n",
        "\n",
        "    # Convert data to DataFrame\n",
        "    df = pd.DataFrame(data, columns=headers)\n",
        "    dfs[sheet_name] = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuaI5x4prUxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491f37c6-f3ea-4f44-884a-3470dd438f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrames:\n",
            "\n",
            "DataFrame: X_train_sim_imp_wNA_dt_rfe\n",
            "\n",
            "DataFrame: X_val_sim_imp_wNA_dt_rfe\n",
            "\n",
            "DataFrame: test_df_sim_imp_wNA_dt_rfe\n",
            "\n",
            "DataFrame: y_train\n",
            "\n",
            "DataFrame: y_val\n",
            "['X_train_sim_imp_wNA_dt_rfe', 'X_val_sim_imp_wNA_dt_rfe', 'test_df_sim_imp_wNA_dt_rfe', 'y_train', 'y_val']\n"
          ]
        }
      ],
      "source": [
        "# Access your DataFrames from the dictionary `dfs`\n",
        "print(\"\\nDataFrames:\")\n",
        "for name, df in dfs.items():\n",
        "    print(f\"\\nDataFrame: {name}\")\n",
        "    name = df\n",
        "\n",
        "print(sheet_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXYo-zt92_ii"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, x_test, y_train, y_val = dfs.items()\n",
        "x_train_m = x_train[1]\n",
        "x_val_m = x_val[1]\n",
        "x_test_m = x_test[1]\n",
        "y_train_m = y_train[1]\n",
        "y_val_m = y_val[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rec4PpvsN2HX"
      },
      "outputs": [],
      "source": [
        "x_train = x_train_m\n",
        "x_val = x_val_m\n",
        "x_test = x_test_m\n",
        "y_train = y_train_m\n",
        "y_val = y_val_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN0oy0ntlK7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a69ba41-1bae-4fb2-90e5-3036c2bb6bcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "None    8\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y_train_m.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnmZQvwcDbzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba9c925-cc37-40bc-f0a8-11da13840fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWyPseJy2_nx"
      },
      "outputs": [],
      "source": [
        "xgb = XGBClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZoEBo7_Sos1"
      },
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "066721U33wix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1048388-1fde-4abf-dae7-a543ce3316c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'colsample_bytree': 0.7473544037332349, 'learning_rate': 0.21473859738014883, 'max_depth': 29, 'min_child_weight': 0, 'n_estimators': 630, 'subsample': 0.8439761626945282}\n",
            "Best cross-validation score: 0.5856138754704786\n",
            "Accuracy on validation set with best estimator: 0.5809\n",
            "Precision on validation set with best estimator: 0.5809\n",
            "Recall on validation set with best estimator: 0.5809\n"
          ]
        }
      ],
      "source": [
        "random_state = 42\n",
        "\n",
        "# Define the parameter distributions\n",
        "param_dist = {\n",
        "    'max_depth': randint(10, 40),  # XGBClassifier parameters\n",
        "    'min_child_weight': randint(0, 3),\n",
        "    'subsample': uniform(0.5, 0.4),\n",
        "    'colsample_bytree': uniform(0.5, 0.4),\n",
        "    'learning_rate': uniform(0.1, 0.3),\n",
        "    'n_estimators': randint(500, 1500)\n",
        "}\n",
        "\n",
        "\n",
        "xgb = XGBClassifier(objective='multi:softmax', num_class=8, n_jobs=-1)\n",
        "\n",
        "# Instantiate RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=xgb,\n",
        "                                   param_distributions=param_dist,\n",
        "                                   n_iter=50,  # Number of parameter settings that are sampled\n",
        "                                   scoring='accuracy',\n",
        "                                   cv=3,\n",
        "                                   verbose=1,\n",
        "                                   n_jobs=-1,\n",
        "                                   random_state=42)\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "random_search.fit(x_train, y_train_encoded)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best parameters found:\", random_search.best_params_)\n",
        "print(\"Best cross-validation score:\", random_search.best_score_)\n",
        "\n",
        "# Get the best estimator\n",
        "best_xgb_model = random_search.best_estimator_\n",
        "\n",
        "# Predict on validation set with the best estimator\n",
        "y_pred = best_xgb_model.predict(x_val)\n",
        "\n",
        "# Evaluate accuracy with the best estimator\n",
        "accuracy_best = accuracy_score(y_val_encoded, y_pred)\n",
        "print(f\"Accuracy on validation set with best estimator: {accuracy_best:.4f}\")\n",
        "\n",
        "# Evaluate precision with the best estimator\n",
        "precision_best = precision_score(y_val_encoded, y_pred, average='micro')\n",
        "print(f\"Precision on validation set with best estimator: {precision_best:.4f}\")\n",
        "\n",
        "# Evaluate precision with the best estimator\n",
        "recall_best = recall_score(y_val_encoded, y_pred, average='micro')\n",
        "print(f\"Recall on validation set with best estimator: {recall_best:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g47RXCsSgJ9b",
        "outputId": "f941949e-0b4f-42b9-87b1-6e5c76a5d4ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11877,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val_encoded, y_pred)\n",
        "\n",
        "# Create a DataFrame for the confusion matrix for better visualization\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=[i+1 for i in range(len(conf_matrix))],\n",
        "                              columns=[i+1 for i in range(len(conf_matrix))])\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d', cmap='Blues')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pNdaQUlEPfHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJaMbytvO0w2"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja33RMFbOz3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f99c74-a504-4edb-b367-797696187728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
            "66 fits failed out of a total of 150.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "26 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.5220613  0.51069386\n",
            " 0.46044548        nan 0.55871085        nan        nan        nan\n",
            "        nan        nan 0.52492423 0.50875721 0.55965815        nan\n",
            " 0.51524084        nan 0.52719772        nan 0.51919844 0.46105595\n",
            " 0.52433481 0.46050864        nan 0.529787   0.52677674        nan\n",
            " 0.56346833 0.563742          nan 0.45928769 0.55951079 0.52031409\n",
            " 0.46074022        nan        nan 0.56193162 0.5155987         nan\n",
            " 0.45983501 0.52761877        nan 0.45899297 0.51164114        nan\n",
            "        nan 0.51928265]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'n_estimators': 1300, 'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 30}\n",
            "Best cross-validation score: 0.5637419989575297\n",
            "Accuracy on validation set with best estimator: 0.5629\n",
            "Precision on validation set with best estimator: 0.5629\n",
            "Recall on validation set with best estimator: 0.5629\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [900, 1100, 1300],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [30, 50],\n",
        "    'min_samples_leaf': [5, 10],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Instantiate the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(estimator=random_forest,\n",
        "                                   param_distributions=param_grid,\n",
        "                                   n_iter=50,  # Number of parameter settings that are sampled\n",
        "                                   scoring='accuracy',\n",
        "                                   cv=3,\n",
        "                                   verbose=1,\n",
        "                                   n_jobs=-1,\n",
        "                                   random_state=42)\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "random_search.fit(x_train, y_train_encoded)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best parameters found:\", random_search.best_params_)\n",
        "print(\"Best cross-validation score:\", random_search.best_score_)\n",
        "\n",
        "# Get the best estimator\n",
        "best_rf_classifier = random_search.best_estimator_\n",
        "\n",
        "# Predict on the validation set with the best estimator\n",
        "y_pred_best = best_rf_classifier.predict(x_val)\n",
        "\n",
        "# Evaluate accuracy with the best estimator\n",
        "accuracy_best = accuracy_score(y_val_encoded, y_pred_best)\n",
        "print(f\"Accuracy on validation set with best estimator: {accuracy_best:.4f}\")\n",
        "\n",
        "# Evaluate precision with the best estimator\n",
        "precision_best = precision_score(y_val_encoded, y_pred_best, average='micro')\n",
        "print(f\"Precision on validation set with best estimator: {precision_best:.4f}\")\n",
        "\n",
        "# Evaluate precision with the best estimator\n",
        "recall_best = recall_score(y_val_encoded, y_pred_best, average='micro')\n",
        "print(f\"Recall on validation set with best estimator: {recall_best:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDWHLGsPx8X9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7141cf5-19a7-430d-a020-60baa6af436d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on validation set with best estimator: 0.5629\n",
            "Precision on validation set with best estimator: 0.5629\n"
          ]
        }
      ],
      "source": [
        "# Evaluate accuracy with the best estimator\n",
        "accuracy_best = accuracy_score(y_val_encoded, y_pred_best)\n",
        "print(f\"Accuracy on validation set with best estimator: {accuracy_best:.4f}\")\n",
        "\n",
        "# Evaluate precision with the best estimator\n",
        "precision_best = precision_score(y_val_encoded, y_pred_best, average='micro')\n",
        "print(f\"Precision on validation set with best estimator: {precision_best:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1lSz9j_gXZ0m7HP7tJVfRUXL19g0fMbGm",
      "authorship_tag": "ABX9TyPSmoIWKfyRku6Trme2vD+3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}