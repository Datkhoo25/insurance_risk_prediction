{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Datkhoo25/insurance_risk_prediction/blob/main/8_(XGB%2C_RF)_RFE_DT_Bayes_Impute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69OhFAnVx55a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55682984-5d84-433f-f703-625aba7db69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', timeout_ms=300000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r183ZGTona4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openpyxl\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "from scipy.optimize import fmin_powell\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import ensemble\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,  roc_auc_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, r2_score\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Fn2wsFa_EL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f846d0-fded-46bc-9ec2-b3fafd40ed72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tz_IeV32WKRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f71c2d-fce0-4478-e59f-bdc988b9fc2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-670abaa5fb26>:13: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  import kerastuner as kt\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-tuner\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.initializers import HeNormal, GlorotNormal, LecunNormal\n",
        "\n",
        "from keras import regularizers\n",
        "from keras.layers import Dropout\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "\n",
        "import kerastuner as kt\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner import Objective\n",
        "\n",
        "from keras.callbacks import History\n",
        "from keras.callbacks import Callback, EarlyStopping\n",
        "from keras.metrics import Accuracy, Recall, Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0ukCAVRrNry"
      },
      "outputs": [],
      "source": [
        "# Specify the path to your Excel file\n",
        "workbook_path = '/content/drive/MyDrive/Colab Notebooks/Insurance Dataset/Preprocessing_Checkpoint/bayes_Impute_wNA_dt_rfe.xlsx'\n",
        "\n",
        "# Load the workbook\n",
        "wb = openpyxl.load_workbook(workbook_path)\n",
        "\n",
        "# Get sheet names\n",
        "sheet_names = wb.sheetnames\n",
        "\n",
        "# Container for DataFrames\n",
        "dfs = {}\n",
        "\n",
        "# Iterate through each sheet\n",
        "for sheet_name in sheet_names:\n",
        "    print(f\"\\nSheet: {sheet_name}\")\n",
        "    sheet = wb[sheet_name]\n",
        "\n",
        "    # Extract headers (first row)\n",
        "    headers = [cell.value for cell in sheet[1]]\n",
        "    # print(f\"Headers: {headers}\")\n",
        "\n",
        "    # Extract data rows\n",
        "    data = []\n",
        "    for row in sheet.iter_rows(min_row=2, values_only=True):\n",
        "        data.append(row)\n",
        "    # print(\"Data:\")\n",
        "    # for row in data:\n",
        "    #     print(row)\n",
        "\n",
        "    # Convert data to DataFrame\n",
        "    df = pd.DataFrame(data, columns=headers)\n",
        "    dfs[sheet_name] = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuaI5x4prUxn"
      },
      "outputs": [],
      "source": [
        "# Access your DataFrames from the dictionary `dfs`\n",
        "print(\"\\nDataFrames:\")\n",
        "for name, df in dfs.items():\n",
        "    print(f\"\\nDataFrame: {name}\")\n",
        "    name = df\n",
        "\n",
        "print(sheet_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXYo-zt92_ii"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, x_test, y_train, y_val = dfs.items()\n",
        "x_train_m = x_train[1]\n",
        "x_val_m = x_val[1]\n",
        "x_test_m = x_test[1]\n",
        "y_train_m = y_train[1]\n",
        "y_val_m = y_val[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rec4PpvsN2HX"
      },
      "outputs": [],
      "source": [
        "x_train = x_train_m\n",
        "x_val = x_val_m\n",
        "x_test = x_test_m\n",
        "y_train = y_train_m\n",
        "y_val = y_val_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvE3waWc2_lI"
      },
      "outputs": [],
      "source": [
        "print(x_train_m.shape, y_train_m.shape)\n",
        "print(x_val_m.shape, y_val_m.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN0oy0ntlK7q"
      },
      "outputs": [],
      "source": [
        "y_train_m.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnmZQvwcDbzg"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWyPseJy2_nx"
      },
      "outputs": [],
      "source": [
        "xgb = XGBClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZoEBo7_Sos1"
      },
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "066721U33wix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4161580d-73e9-49a1-f379-bd7772558cf7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'colsample_bytree': 0.7473544037332349, 'learning_rate': 0.21473859738014883, 'max_depth': 29, 'min_child_weight': 0, 'n_estimators': 630, 'subsample': 0.8439761626945282}\n",
            "Best cross-validation score: 0.5394283779147079\n",
            "Accuracy on validation set with best estimator: 0.5445\n",
            "Precision on validation set with best estimator: 0.5445\n",
            "Recall on validation set with best estimator: 0.5445\n"
          ]
        }
      ],
      "source": [
        "random_state = 42\n",
        "\n",
        "# Define the parameter distributions\n",
        "param_dist = {\n",
        "    'max_depth': randint(10, 40),  # XGBClassifier parameters\n",
        "    'min_child_weight': randint(0, 3),\n",
        "    'subsample': uniform(0.5, 0.4),\n",
        "    'colsample_bytree': uniform(0.5, 0.4),\n",
        "    'learning_rate': uniform(0.1, 0.3),\n",
        "    'n_estimators': randint(500, 1500)\n",
        "}\n",
        "\n",
        "\n",
        "xgb = XGBClassifier(objective='multi:softmax', num_class=8, n_jobs=-1)\n",
        "\n",
        "# Instantiate RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=xgb,\n",
        "                                   param_distributions=param_dist,\n",
        "                                   n_iter=50,  # Number of parameter settings that are sampled\n",
        "                                   scoring='accuracy',\n",
        "                                   cv=3,\n",
        "                                   verbose=1,\n",
        "                                   n_jobs=-1,\n",
        "                                   random_state=42)\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "random_search.fit(x_train, y_train_encoded)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best parameters found:\", random_search.best_params_)\n",
        "print(\"Best cross-validation score:\", random_search.best_score_)\n",
        "\n",
        "# Get the best estimator\n",
        "best_xgb_model = random_search.best_estimator_\n",
        "\n",
        "# Predict on validation set with the best estimator\n",
        "y_pred = best_xgb_model.predict(x_val)\n",
        "\n",
        "# Evaluate accuracy with the best estimator\n",
        "accuracy_best = accuracy_score(y_val_encoded, y_pred)\n",
        "print(f\"Accuracy on validation set with best estimator: {accuracy_best:.4f}\")\n",
        "\n",
        "# Evaluate precision with the best estimator\n",
        "precision_best = precision_score(y_val_encoded, y_pred, average='micro')\n",
        "print(f\"Precision on validation set with best estimator: {precision_best:.4f}\")\n",
        "\n",
        "# Evaluate precision with the best estimator\n",
        "recall_best = recall_score(y_val_encoded, y_pred, average='micro')\n",
        "print(f\"Recall on validation set with best estimator: {recall_best:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJaMbytvO0w2"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja33RMFbOz3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6117e45-7239-4243-8871-f7f071c652a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'n_estimators': 900, 'min_samples_split': 30, 'min_samples_leaf': 5, 'max_features': 'auto', 'max_depth': 20}\n",
            "Best cross-validation score: 0.529071271584038\n",
            "Accuracy on validation set with best estimator: 0.5319\n",
            "Precision on validation set with best estimator: 0.5319\n",
            "Recall on validation set with best estimator: 0.5319\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [900, 1100, 1300],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [30, 50],\n",
        "    'min_samples_leaf': [5, 10],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Instantiate the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(estimator=random_forest,\n",
        "                                   param_distributions=param_grid,\n",
        "                                   n_iter=50,  # Number of parameter settings that are sampled\n",
        "                                   scoring='accuracy',\n",
        "                                   cv=3,\n",
        "                                   verbose=1,\n",
        "                                   n_jobs=-1,\n",
        "                                   random_state=42)\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "random_search.fit(x_train, y_train_encoded)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best parameters found:\", random_search.best_params_)\n",
        "print(\"Best cross-validation score:\", random_search.best_score_)\n",
        "\n",
        "# Get the best estimator\n",
        "best_rf_classifier = random_search.best_estimator_\n",
        "\n",
        "# Predict on the validation set with the best estimator\n",
        "y_pred_best = best_rf_classifier.predict(x_val)\n",
        "\n",
        "# Evaluate accuracy with the best estimator\n",
        "accuracy_best = accuracy_score(y_val_encoded, y_pred_best)\n",
        "print(f\"Accuracy on validation set with best estimator: {accuracy_best:.4f}\")\n",
        "\n",
        "# Evaluate precision with the best estimator\n",
        "precision_best = precision_score(y_val_encoded, y_pred_best, average='micro')\n",
        "print(f\"Precision on validation set with best estimator: {precision_best:.4f}\")\n",
        "\n",
        "# Evaluate precision with the best estimator\n",
        "recall_best = recall_score(y_val_encoded, y_pred_best, average='micro')\n",
        "print(f\"Recall on validation set with best estimator: {recall_best:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDWHLGsPx8X9"
      },
      "outputs": [],
      "source": [
        "# Evaluate accuracy with the best estimator\n",
        "accuracy_best = accuracy_score(y_val_encoded, y_pred_best)\n",
        "print(f\"Accuracy on validation set with best estimator: {accuracy_best:.4f}\")\n",
        "\n",
        "# Evaluate precision with the best estimator\n",
        "precision_best = precision_score(y_val_encoded, y_pred_best, average='micro')\n",
        "print(f\"Precision on validation set with best estimator: {precision_best:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1lSz9j_gXZ0m7HP7tJVfRUXL19g0fMbGm",
      "authorship_tag": "ABX9TyN4lIZUKrgDjIwKZq6R0Yfe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}